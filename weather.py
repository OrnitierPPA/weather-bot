import requests
from bs4 import BeautifulSoup
import json
import re

# –§—É–Ω–∫—Ü–∏—è, –≤—Å—Ç–∞–≤–ª—è—é—â–∞—è ':' –≤ —Å–ø–∏—Å–∫–∞ –æ –≤—Ä–µ–º–µ–Ω–∏. –°–æ–∑–¥–∞–Ω–∞, –¥–∞–±—ã –∏–∑–±–µ–∂–∞—Ç—å "1:000, 1:200" –≤–º–µ—Å—Ç–æ "10:00, 12:00"
def f(line):
    # –ï—Å–ª–∏ –¥–ª–∏–Ω–∞ –ª–∏–Ω–∏–∏ –±–æ–ª–µ–µ 3 —Å–∏–º–≤–æ–ª–æ–≤, –º–µ–∂–¥—É 2 –∏ 3 —Ü–∏—Ñ—Ä–æ–π —Å—Ç–∞–≤–∏—Ç—Å—è ':' (10:00)
    if len(line) > 3:
        return f'{line[:2]}:{line[2:]}'
    # –ò–Ω–∞—á–µ, ':' —Å—Ç–∞–≤–∏—Ç—Å—è –º–µ–∂–¥—É 1 –∏ 2 —Ü–∏—Ñ—Ä–∞–º–∏. (1:00)
    return f'{line[:1]}:{line[1:]}'

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –Ω—É–∂–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞
def city(cityname, mode, area):
    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0"
    }
    city = cityname+' ' # –ø—Ä–æ–±–µ–ª —Å–≤—è–∑–∞–Ω —Å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é HTML –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å–∞–π—Ç–∞, –∫–æ—Å—Ç—ã–ª—å, –±–µ–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∏—Å–∫
    link = f"https://www.gismeteo.ru/search/{city}"

    q = requests.get(url=link, headers=headers)
    result = q.text
    soup = BeautifulSoup(result, 'lxml')
    cityname = soup.find_all('div', class_='catalog-item-link')
    ashi = [] # —Å–ø–∏—Å–æ–∫ –¥–ª—è –≤—Å–µ—Ö 'a' —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å—Å—ã–ª–∫–∞–º–∏ –≤ –ø–æ–∏—Å–∫–µ, —Å—Ä–µ–¥–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∏–¥—ë—Ç –ø–æ–∏—Å–∫ –æ–¥–Ω–æ–π –Ω—É–∂–Ω–æ–π
    for a in cityname: # —Ü–∏–∫–ª, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –≤–∞–º —É–∑–Ω–∞—Ç—å –ø–æ–≥–æ–¥—É –≤ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º –ü–∞—Ä–∏–∂–µ, –∞ –Ω–µ –±–∞—à–∫–∏—Ä—Å–∫–æ–º
        a = a.find_all('a', class_='link-item')
        for href in a:
            if href.find(text=re.compile(city)): # –∏–∑-–∑–∞ –Ω–∞–ª–∏—á–∏—è <i> —Ç–µ–≥–æ–≤ –≤–Ω—É—Ç—Ä–∏ <a>, –Ω—É–∂–Ω–∞—è —Å—Ç—Ä–æ–∫ –Ω–µ –∏—â–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é (text=city), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å—Ç—ã–ª–∏ 
                if len(href.text) == len(city):
                    ashi.append(href)
    for link in ashi: # –ø–µ—Ä–µ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–π –∏–∑ —Å—Å—ã–ª–æ–∫, –ø–æ–∫–∞ –Ω–µ –Ω–∞–π–¥—ë–º —Ç—É, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –Ω—É–∂–Ω–æ–º –Ω–∞–º —Ä–∞–π–æ–Ω–µ
        href = link.get('href')
        q = requests.get(url=f'https://www.gismeteo.ru{href}', headers=headers)
        result = q.text
        soup = BeautifulSoup(result, 'lxml')
        areas = soup.find_all('a', class_='breadcrumbs-link')
        for i in areas:
            if i.text == area:
                link = link.get('href')
                if mode.lower() == '–∑–∞–≤—Ç—Ä–∞':
                    weather_tomorrow(link, city)
                elif mode.lower() == '–º–µ—Å—è—Ü':
                    weather_30(link, city)
                else:
                    weather_today(link, city)
                return print('–í—ã–ø–æ–ª–Ω–µ–Ω–æ')
  
def weather_today(link, city):
    city = city.strip()
    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0"
    }
    
    q = requests.get(url=f'https://www.gismeteo.ru{link}', headers=headers)
    result = q.text
    soup = BeautifulSoup(result, 'lxml')
    # –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –¥–æ–∂–¥–µ. –í–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–¥–Ω—É –∏–∑ —Å—Ç—Ä–æ–∫.
    rane_dir = [x.text for x in soup.select('div.widget-row-precipitation-bars div.row-item div.item-unit')]
    for x in range(0,8):
        if rane_dir[x] == '0':
            rane_dir[x] = f'–û—Å–∞–¥–∫–æ–≤ –Ω–µ—Ç ‚õÖ'
        elif rane_dir[x] == '':
            rane_dir[x] = f'–í–æ–∑–º–æ–∂–µ–Ω –¥–æ–∂–¥—å(–Ω/–¥ –∫–∞–ø.) üåßÔ∏è'
        else:
            rane_dir[x] = f'–í–æ–∑–º–æ–∂–µ–Ω –¥–æ–∂–¥—å({rane_dir[x]} –∫–∞–ø.) üåßÔ∏è'
    
    # –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –≤—Ä–µ–º–µ–Ω–∏, –∑–∞—Ç–µ–º –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–æ–µ—Ç–æ—á–∏–µ –º–µ–∂–¥—É —Ü–∏—Ñ—Ä–∞–º–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ñ—É–Ω–∫—Ü–∏–∏ f
    time_dir = [x.text for x in soup.select('div.widget-row-time div.row-item span')]
    time_dir = [line.strip() for line in time_dir]
    data_time = list(map(f, time_dir))

    # –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –≤ —Ü–µ–ª—å—Å–∏—è—Ö
    temp_dir = [x.text for x in soup.select('div.widget-oneday span.unit_temperature_c')]

    # –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–∞–Ω–µ–µ —Å–æ–±—Ä–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ –æ –¥–æ–∂–¥–µ
    gen_inf = list(zip(temp_dir, rane_dir))

    # –°–æ–∑–¥–∞—ë—Ç —Å–ª–æ–≤–∞—Ä—å –∏ –≤–Ω–æ—Å–∏—Ç –≤ –Ω–µ–≥–æ –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ü–∏–∫–ª–∞
    data = {
    f'–°–ø–∏—Å–æ–∫ –ø–æ–≥–æ–¥—ã –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å, {city}': "\n"
    }
    
    # –ù–∞ –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é –æ—Ç 0 –¥–æ 7 –±–µ—Ä—ë—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–ø–∏—Å–∫–æ–≤ —Ç–æ–π –∂–µ –ø–æ–∑–∏—Ü–∏–∏
    for i in range(8):
        data[data_time[i]] = ', '.join(gen_inf[i])

    # –°–æ–∑–¥–∞—ë—Ç json —Ñ–∞–π–ª –∏ –ø–æ–º–µ—â–∞–µ—Ç –≤ –Ω–µ–≥–æ —Å–ª–æ–≤–∞—Ä—å
    with open('weather_today.json', 'w', encoding="utf-8") as json_file:
        json.dump(data, json_file, indent=4, ensure_ascii=False)

# –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ–¥–æ–±–Ω–æ –ø—Ä–æ—à–ª–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –Ω–æ —Å –¥—Ä—É–≥–æ–π —Å—Å—ã–ª–∫–æ–π
def weather_tomorrow(link, city):
    city = city.strip()
    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0"
    }
    
    q = requests.get(url=f'https://www.gismeteo.ru{link}tomorrow/', headers=headers)
    result = q.text
    soup = BeautifulSoup(result, 'lxml')
   
    rane_dir = [x.text for x in soup.select('div.widget-row-precipitation-bars div.row-item div.item-unit')]
    for x in range(0,8):
        if rane_dir[x] == '0':
            rane_dir[x] = f'–û—Å–∞–¥–∫–æ–≤ –Ω–µ—Ç ‚õÖ'
        elif rane_dir[x] == '':
            rane_dir[x] = f'–í–æ–∑–º–æ–∂–µ–Ω –¥–æ–∂–¥—å(–Ω/–¥ –∫–∞–ø.) üåßÔ∏è'
        else:
            rane_dir[x] = f'–í–æ–∑–º–æ–∂–µ–Ω –¥–æ–∂–¥—å({rane_dir[x]} –∫–∞–ø.) üåßÔ∏è'
    

    time_dir = [x.text for x in soup.select('div.widget-row-time div.row-item span')]
    time_dir = [line.strip() for line in time_dir]
    data_time = list(map(f, time_dir))

    temp_dir = [x.text for x in soup.select('div.widget-oneday span.unit_temperature_c')]

    gen_inf = list(zip(temp_dir, rane_dir))

    data = {
    f'–°–ø–∏—Å–æ–∫ –ø–æ–≥–æ–¥—ã –Ω–∞ –∑–∞–≤—Ç—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å, {city}': "\n"
    }
    
    for i in range(8):
        data[data_time[i]] = ', '.join(gen_inf[i])

    with open('weather_tomorrow.json', 'w', encoding="utf-8") as json_file:
        json.dump(data, json_file, indent=4, ensure_ascii=False)

# –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ–¥–æ–±–Ω–æ –ø—Ä–æ—à–ª–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –Ω–æ —Å –¥—Ä—É–≥–æ–π —Å—Å—ã–ª–∫–æ–π
def weather_30(link, city):
    city = city.strip()
    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0"
    }
    
    q = requests.get(url=f'https://www.gismeteo.ru{link}month/', headers=headers)
    result = q.text
    soup = BeautifulSoup(result, 'lxml')

    # –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —á–∏—Å–ª–∞—Ö
    date = [x.text for x in soup.select('div.widget-body a.row-item div.date')]
    date_norm = []
    for line in date:
        line = ''.join(vol for vol in line if vol.isalnum())
    
        if len(line) > 2:
            if len(line) == 4:
                line = line[:1] + ' ' + line[-3:]
            else:
                line = line[:2] + ' ' + line[-3:]

        date_norm.append(line)

    date_day = []
    
    # –¶–∏–∫–ª –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ —Å–ø–∏—Å–æ–∫ date_day –¥–µ–Ω—å –∏ –º–µ—Å—è—Ü
    for day in date_norm:
        if len(day) > 2:
            if day[1:][:2] == ' ':
                month = day[1:]
            else: 
                month = day[2:]
        
        month = month.strip()
        
        if len(day) <= 2:
            day = day + ' ' + month
        
        date_day.append(day)

    # –°–æ–±–∏—Ä–∞—é—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
    minT = [x.text for x in soup.select('div.widget-body a.row-item div.temp div.mint span.unit_temperature_c')]
    maxT = [x.text for x in soup.select('div.widget-body a.row-item div.temp div.maxt span.unit_temperature_c')]
    
    # —Å—Å–æ–∑–¥–∞—ë—Ç —Å–ª–æ–≤–∞—Ä—å –∏ —Å –ø–æ–º–æ—â—å—é —Ü–∏–∫–ª–∞ –Ω–∞–ø–æ–ª–Ω—è–µ—Ç—å –µ–≥–æ –¥–∞–Ω–Ω—ã–º–∏ —Å–æ–±—Ä–∞–Ω–Ω—ã–º–∏ —Ä–∞–Ω–µ–µ
    data = {
    f'–°–ø–∏—Å–æ–∫ –ø–æ–≥–æ–¥—ã –Ω–∞ –º–µ—Å—è—Ü, {city}': '\n'
    }

    for i in range(42):
        data[date_day[i]] = '–º–∞–∫—Å. {0}, –º–∏–Ω. {1}'.format(maxT[i], minT[i])

    # –°–æ–∑–¥–∞—ë—Ç json —Ñ–∞–π–ª –∏ –ø–æ–º–µ—â–∞–µ—Ç –≤ –Ω–µ–≥–æ —Å–ª–æ–≤–∞—Ä—å
    with open('weather_30day.json', 'w', encoding="utf-8") as json_file:
        json.dump(data, json_file, indent=4, ensure_ascii=False)

def main():
    city()

if __name__ == '__main__':
    main()